{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from konlpy.tag import Kkma\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> dict:\n",
    "    kkma = Kkma()\n",
    "    tokens = kkma.morphs(text)\n",
    "    pos_tokens = kkma.pos(text)\n",
    "    return {'text': text, 'tokens': tokens, 'pos': pos_tokens}\n",
    "\n",
    "def get_string_length(text: str) -> int:\n",
    "    return(len(text))\n",
    "def get_num_tokens(tokens: list) -> int:\n",
    "    return(len(tokens))\n",
    "def find_sent_id(tokens: list) -> list:\n",
    "    ids = []\n",
    "    for i, tok in enumerate(tokens):\n",
    "        found = re.findall('[.?!]+', tok)\n",
    "        if(bool(found)):\n",
    "            ids.append(i)\n",
    "    return ids\n",
    "def split_sentence(sent_ids: list, tokens: list)-> list:  \n",
    "    sentences = []\n",
    "    start = 0\n",
    "    for i in sent_ids:\n",
    "        sentences.append(tokens[start:i+1])\n",
    "        start = i+1\n",
    "    return sentences\n",
    "def split_pos_sentence(sent_ids: list, pos: list)-> list:  \n",
    "    sentences = []\n",
    "    start = 0\n",
    "    for i in sent_ids:\n",
    "        sent_both = pos[start:i+1] #get the sentence\n",
    "        sent_tag = list(map(lambda tag: tag[1], sent_both))#get only the pos tags\n",
    "        sentences.append(sent_tag)#append\n",
    "        start = i+1\n",
    "    return sentences\n",
    "def get_num_sentences(tokens:list, pos:list):\n",
    "    sent_ids = find_sent_id(tokens)\n",
    "    sentences = split_sentence(sent_ids, tokens)\n",
    "    pos_sentences = split_pos_sentence(sent_ids, pos)\n",
    "    return len(sent_ids), sentences, pos_sentences\n",
    "def get_num_token_sentences(sentences: list) -> list:\n",
    "    num_tokens = []\n",
    "    for sentence in sentences:\n",
    "        num_tokens.append(len(sentence))\n",
    "    return num_tokens\n",
    "\n",
    "def simple_analysis(data):\n",
    "    \n",
    "    text = data['text']\n",
    "    tokens = data['tokens']\n",
    "    pos = data['pos']\n",
    "\n",
    "    all_analysis = {}\n",
    "\n",
    "    all_analysis['string_length'] = get_string_length(text)\n",
    "    all_analysis['num_tokens'] = get_num_tokens(tokens)\n",
    "    num_sentences, sentences, pos_sentences = get_num_sentences(tokens, pos)\n",
    "    num_token_sentences = get_num_token_sentences(sentences)\n",
    "    all_analysis['num_sentences'] = num_sentences\n",
    "    all_analysis['num_token_sentences'] = num_token_sentences\n",
    "    data['sentence_tokens'] = sentences\n",
    "    data['sentence_pos'] = pos_sentences\n",
    "    \n",
    "    return data, all_analysis\n",
    "def get_rel_freq(freq: dict):\n",
    "    freq = pd.Series(freq, dtype = \"float64\")\n",
    "    tot = freq.sum()\n",
    "    return (freq/tot).to_dict()\n",
    "def get_pos_freq(article: list[list]) -> dict:\n",
    "    pos_freq = {}\n",
    "    s_freq = []\n",
    "    s_rel_freq = []\n",
    "    article_freq = dict()\n",
    "\n",
    "    for sentence in article:\n",
    "        sentence_freq = dict(Counter(sentence))\n",
    "        s_freq.append(sentence_freq)\n",
    "        s_rel_freq.append(get_rel_freq(sentence_freq))\n",
    "        for (key, freq) in sentence_freq.items():\n",
    "            if key in article_freq.keys():\n",
    "                article_freq[key] = article_freq[key] + freq\n",
    "            else:\n",
    "                article_freq[key] = freq\n",
    "\n",
    "    pos_freq['s_freq'] = s_freq\n",
    "    pos_freq['s_rel_freq'] = s_rel_freq\n",
    "    pos_freq['a_freq'] = article_freq\n",
    "    pos_freq['a_rel_freq'] = get_rel_freq(article_freq)\n",
    "        \n",
    "    return pos_freq \n",
    "def calRelPosition(sentence_pos, num_token_sentences):\n",
    "    for i, sentence in enumerate(sentence_pos):\n",
    "        pos = np.array(sentence)\n",
    "        result = {}\n",
    "        for tag in set(pos):\n",
    "            indices = np.where(pos == tag)[0][0]\n",
    "            result[tag] = indices/num_token_sentences[i]       \n",
    "    return result\n",
    "def get_more_features(data, all_analysis):\n",
    "    \n",
    "    num_token_sentences = np.array(all_analysis['num_token_sentences'])\n",
    "    num_token_type = len(all_analysis['pos_freq']['s_freq'])\n",
    "    token_variety = (num_token_type / num_token_sentences)\n",
    "    all_analysis['token_variety'] = token_variety\n",
    "    sentence_pos = data['sentence_pos']\n",
    "    rel_position = calRelPosition(sentence_pos, num_token_sentences)\n",
    "    all_analysis['rel_position'] = rel_position\n",
    "    return all_analysis\n",
    "\n",
    "def analysis(data):\n",
    "    data, all_analysis = simple_analysis(data)\n",
    "    all_analysis['pos_freq'] = get_pos_freq(data['sentence_pos'])\n",
    "    all_analysis = get_more_features(data, all_analysis)\n",
    "    return data, all_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NNG',\n",
       "  'JKS',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'ETD',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'VV',\n",
       "  'ETD',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'VV',\n",
       "  'ECS',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'VV',\n",
       "  'EPT',\n",
       "  'EFN',\n",
       "  'SF'],\n",
       " ['NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'JX',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKS',\n",
       "  'VV',\n",
       "  'ETD',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'ETD',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'VV',\n",
       "  'ETD',\n",
       "  'OL',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'EPT',\n",
       "  'EFN',\n",
       "  'SF'],\n",
       " ['OL',\n",
       "  'NNG',\n",
       "  'JX',\n",
       "  'NNG',\n",
       "  'XSN',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'VV',\n",
       "  'ECD',\n",
       "  'NNG',\n",
       "  'NR',\n",
       "  'NNM',\n",
       "  'NR',\n",
       "  'NNM',\n",
       "  'JX',\n",
       "  'JX',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'ETD',\n",
       "  'NNB',\n",
       "  'VV',\n",
       "  'EPT',\n",
       "  'EPT',\n",
       "  'ETD',\n",
       "  'SS',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'JKG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'SS',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKS',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'ETD',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'JX',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'ECD',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'EPT',\n",
       "  'ETD',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'VV',\n",
       "  'ECE',\n",
       "  'VXV',\n",
       "  'EFN',\n",
       "  'SF'],\n",
       " ['MAG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JX',\n",
       "  'NNG',\n",
       "  'NR',\n",
       "  'NNM',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JC',\n",
       "  'NNG',\n",
       "  'SP',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNB',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'OL',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'EPT',\n",
       "  'EFN',\n",
       "  'SF'],\n",
       " ['OL',\n",
       "  'NNG',\n",
       "  'JX',\n",
       "  'NNG',\n",
       "  'NR',\n",
       "  'NNM',\n",
       "  'JKM',\n",
       "  'JX',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKM',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'JKO',\n",
       "  'VV',\n",
       "  'EPT',\n",
       "  'ECE',\n",
       "  'SP',\n",
       "  'OL',\n",
       "  'NNG',\n",
       "  'JC',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'NNB',\n",
       "  'NR',\n",
       "  'NNM',\n",
       "  'JKO',\n",
       "  'NNG',\n",
       "  'NNG',\n",
       "  'XSV',\n",
       "  'EPT',\n",
       "  'EFN',\n",
       "  'SF']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JC': 0.5675675675675675,\n",
       " 'XSV': 0.8918918918918919,\n",
       " 'OL': 0.0,\n",
       " 'JKO': 0.3783783783783784,\n",
       " 'EPT': 0.43243243243243246,\n",
       " 'VV': 0.40540540540540543,\n",
       " 'NNG': 0.02702702702702703,\n",
       " 'SP': 0.4864864864864865,\n",
       " 'JKM': 0.16216216216216217,\n",
       " 'EFN': 0.9459459459459459,\n",
       " 'JX': 0.05405405405405406,\n",
       " 'ECE': 0.4594594594594595,\n",
       " 'SF': 0.972972972972973,\n",
       " 'NNB': 0.7297297297297297,\n",
       " 'NR': 0.10810810810810811,\n",
       " 'NNM': 0.13513513513513514}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calRelPosition(data['sentence_pos'], new_analysis['num_token_sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input  = {}\n",
    "new_input['text']=\"경찰이 미승인 의료기술로 환자를 수술한 의혹을 받는 유명 관절전문병원에 대해 강제수사에 나섰습니다.서울 방배경찰서는 승인 기간이 지난 줄기세포 치료법으로 환자를 수술한 의혹을 받는 A 병원을 압수수색했습니다.A 병원은 제한적 의료기술 승인을 받아 재작년 4월 30일까지만 시술할 수 있었던 '근골격계 질환에서의 자가 지방 줄기세포 치료술'을 기한이 종료된 후에도 지속해서 시술했다는 의혹을 받고 있습니다.앞서 서민민생대책위원회는 지난해 8월 국민건강보험법 위반과 사기, 의료법 위반 등 혐의로 A 병원장을 서울 서부지방검찰청에 고발했습니다.A 병원은 재작년 7월에도 대리수술 혐의로 경찰 수사를 받았고, A 병원장과 의료기구업체 영업사원 등 16명을 불구속 송치했습니다.\"\n",
    "new_input['category'] = \"articles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_input = input()\n",
    "# with open(new_input) as json_file:\n",
    "#     new_input = json.load(json_file)\n",
    "data = new_input['text']\n",
    "category = new_input['category']\n",
    "\n",
    "data = tokenize(data)\n",
    "data, new_analysis = analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['string_length', 'num_tokens', 'num_sentences', 'num_token_sentences', 'pos_freq', 'token_variety', 'rel_position'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_flatten(lst):\n",
    "    result = []\n",
    "    for el in lst:\n",
    "        result.extend(el)\n",
    "    return result\n",
    "def dict_flatten(dct):\n",
    "    result = {}\n",
    "    for k, v in dct.items():\n",
    "            if k in result.keys():\n",
    "                if isinstance(result[k], list):\n",
    "                    result[k].append(v)\n",
    "                else:\n",
    "                    result[k] = [result[k], v]\n",
    "            else:\n",
    "                result[k] = v\n",
    "    return result\n",
    "def list_of_dict(lst):\n",
    "    result = {}\n",
    "    for dct in lst:\n",
    "        for k, v in dct.items():\n",
    "            if k in result.keys():\n",
    "                if isinstance(result[k], list):\n",
    "                    result[k].append(v)\n",
    "                else:\n",
    "                    result[k] = [result[k], v]\n",
    "            else:\n",
    "                result[k] = v\n",
    "    return result\n",
    "def mean_of_dict(dct):\n",
    "    for k,v in dct.items():\n",
    "        dct[k] = np.mean(v)\n",
    "    return dct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NNG': 0.4358974358974359,\n",
       " 'JKS': 0.015384615384615385,\n",
       " 'JKM': 0.05641025641025641,\n",
       " 'JKO': 0.05128205128205128,\n",
       " 'XSV': 0.046153846153846156,\n",
       " 'ETD': 0.046153846153846156,\n",
       " 'VV': 0.046153846153846156,\n",
       " 'ECS': 0.005128205128205128,\n",
       " 'EPT': 0.041025641025641026,\n",
       " 'EFN': 0.02564102564102564,\n",
       " 'SF': 0.02564102564102564,\n",
       " 'JX': 0.041025641025641026,\n",
       " 'OL': 0.02564102564102564,\n",
       " 'XSN': 0.005128205128205128,\n",
       " 'ECD': 0.010256410256410256,\n",
       " 'NR': 0.02564102564102564,\n",
       " 'NNM': 0.02564102564102564,\n",
       " 'NNB': 0.015384615384615385,\n",
       " 'SS': 0.010256410256410256,\n",
       " 'JKG': 0.005128205128205128,\n",
       " 'ECE': 0.010256410256410256,\n",
       " 'VXV': 0.005128205128205128,\n",
       " 'MAG': 0.005128205128205128,\n",
       " 'JC': 0.010256410256410256,\n",
       " 'SP': 0.010256410256410256}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis['pos_freq']['a_rel_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_var = {\n",
    "    \"token_variety\": np.mean(new_analysis['token_variety']),\n",
    "    \"rel_position\": np.mean(new_analysis['token_variety']),\n",
    "    \"num_token_sentences\": np.mean(new_analysis['num_token_sentences']),\n",
    "    \"s_rel_freq\": mean_of_dict(list_of_dict(new_analysis['pos_freq']['s_rel_freq'])),\n",
    "    \"a_rel_freq\": new_analysis['pos_freq']['a_rel_freq'],\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunjangnim",
   "language": "python",
   "name": "hunjangnim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
